{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03: Tensors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A specific type of array is requried in the context of PyTorch based neural nets, called \"tensors\"\n",
    "- Tensors are similar to NumPy arrays but additional specific functionalities needed for deep learning\n",
    "- Brief exploration of PyTorch tensors, accessible from the torch module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create array filled with ones\n",
    "t_array = torch.ones((3, 2))\n",
    "t_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_array = np.ones((3, 2))\n",
    "n_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_array dtype: torch.float32\n",
      "n_array type: float64\n"
     ]
    }
   ],
   "source": [
    "# find the array type with *dtype*\n",
    "\n",
    "print(f\"t_array dtype: {t_array.dtype}\")\n",
    "print(f\"n_array type: {n_array.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[227, 143, 247, 171, 222,  29, 239,  53, 197, 102],\n",
       "        [ 94,  21,  78, 128, 162,  58, 235, 178,  49,  15],\n",
       "        [179,  27, 141,   5, 103,  76, 171,  92,  52, 215],\n",
       "        [212,   3, 116, 172, 193,  84, 236,  48,  77,  49],\n",
       "        [147, 168,  12, 220, 212,  53, 118, 166,  55,  44],\n",
       "        [235, 154,  25,  91, 145, 110,  53, 107,  97, 136],\n",
       "        [205, 104,  74,  98,  14,  96, 109, 182, 197, 159],\n",
       "        [ 29, 145, 105,  77, 155,  23, 124, 179, 142, 247],\n",
       "        [114, 224,  53,  35,  16, 252, 111,  74, 164,  32],\n",
       "        [125, 177,  91, 188, 167, 172,  22,  91,  42,  96]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch implements other funcs to create arrays similar to Numpy\n",
    "# eg. random number arrays:\n",
    "\n",
    "t_random = torch.randint(0, 255, (10, 10))\n",
    "t_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from numpy to tensor\n",
    "t_from_n = torch.tensor(n_array)\n",
    "t_from_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy from tensor\n",
    "\n",
    "t_from_n.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mimshow(t_random);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(t_random);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, broadcasting, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[227, 143, 247, 171, 222,  29, 239,  53, 197, 102],\n",
       "        [ 94,  21,  78, 128, 162,  58, 235, 178,  49,  15],\n",
       "        [179,  27, 141,   5, 103,  76, 171,  92,  52, 215],\n",
       "        [212,   3, 116, 172, 193,  84, 236,  48,  77,  49],\n",
       "        [147, 168,  12, 220, 212,  53, 118, 166,  55,  44],\n",
       "        [235, 154,  25,  91, 145, 110,  53, 107,  97, 136],\n",
       "        [205, 104,  74,  98,  14,  96, 109, 182, 197, 159],\n",
       "        [ 29, 145, 105,  77, 155,  23, 124, 179, 142, 247],\n",
       "        [114, 224,  53,  35,  16, 252, 111,  74, 164,  32],\n",
       "        [125, 177,  91, 188, 167, 172,  22,  91,  42,  96]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([227, 143, 247, 171, 222,  29, 239,  53, 197, 102])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random[0, :]  # row 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[143., 109.,  53., 174.,   7.],\n",
       "        [143., 109.,  53., 174.,   7.],\n",
       "        [143., 109.,  53., 174.,   7.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# broadcasting allows the combining of tensors of different but compatible shapes:\n",
    "torch.ones((3, 5)) * torch.randint(0, 255, (1, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- may need to flatten arrays\n",
    "- eg. to create a fully connected layer in a deep learning network\n",
    "- done in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([227, 143, 247, 171, 222,  29, 239,  53, 197, 102,  94,  21,  78, 128,\n",
       "        162,  58, 235, 178,  49,  15, 179,  27, 141,   5, 103,  76, 171,  92,\n",
       "         52, 215, 212,   3, 116, 172, 193,  84, 236,  48,  77,  49, 147, 168,\n",
       "         12, 220, 212,  53, 118, 166,  55,  44, 235, 154,  25,  91, 145, 110,\n",
       "         53, 107,  97, 136, 205, 104,  74,  98,  14,  96, 109, 182, 197, 159,\n",
       "         29, 145, 105,  77, 155,  23, 124, 179, 142, 247, 114, 224,  53,  35,\n",
       "         16, 252, 111,  74, 164,  32, 125, 177,  91, 188, 167, 172,  22,  91,\n",
       "         42,  96])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random.flatten()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which contiguous dimensions you want to flatten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[41, 17, 11, 35],\n",
       "         [23, 32, 91, 81],\n",
       "         [97,  5, 38,  7]],\n",
       "\n",
       "        [[15, 71, 80, 60],\n",
       "         [86, 62, 65, 40],\n",
       "         [85, 39, 61, 81]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_3d = torch.randint(0, 100, (2, 3, 4))\n",
    "t_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[41, 17, 11, 35, 23, 32, 91, 81, 97,  5, 38,  7],\n",
       "        [15, 71, 80, 60, 86, 62, 65, 40, 85, 39, 61, 81]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(t_3d, start_dim=1, end_dim=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: \n",
    "\n",
    "- use the *view* method, which if possible, returns only a *view* of the array\n",
    "- can pass compatible dimensions to reshape the tensor, or simply use *-1* to completely flatten it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_random = torch.randint(0, 255, (10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 55, 108, 202, 173, 233,  94,  13, 164, 125, 187,  83, 133,  61,  14,\n",
       "          60, 140, 231,  50, 111, 155],\n",
       "        [213, 160,  49,  27, 231,  63,  90, 211,  18, 199, 202, 211, 190, 234,\n",
       "          20, 170,  52, 129,  26,  82],\n",
       "        [175, 103, 161, 248,  86,  90, 206,  20,  14, 176, 183,  67, 172,   5,\n",
       "          49,  23, 244,  22, 144, 170],\n",
       "        [215,  69, 106,  86, 139,  97,  63, 237,  45, 145,  49, 160,  89,   7,\n",
       "         125, 137,  93, 133,  56, 145],\n",
       "        [169,  96,  31, 231, 134,  96,  88,  70,  91, 108, 223,  66,  28, 230,\n",
       "          91, 152,  35,  73, 101, 167]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_random.view(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 55, 108, 202, 173, 233,  94,  13, 164, 125, 187,  83, 133,  61,  14,\n",
       "         60, 140, 231,  50, 111, 155, 213, 160,  49,  27, 231,  63,  90, 211,\n",
       "         18, 199, 202, 211, 190, 234,  20, 170,  52, 129,  26,  82, 175, 103,\n",
       "        161, 248,  86,  90, 206,  20,  14, 176, 183,  67, 172,   5,  49,  23,\n",
       "        244,  22, 144, 170, 215,  69, 106,  86, 139,  97,  63, 237,  45, 145,\n",
       "         49, 160,  89,   7, 125, 137,  93, 133,  56, 145, 169,  96,  31, 231,\n",
       "        134,  96,  88,  70,  91, 108, 223,  66,  28, 230,  91, 152,  35,  73,\n",
       "        101, 167])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten\n",
    "t_random.view(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are dealing with a *view*: If we modify one of the arrays *in place*, the values in the other arrays are changed as well. This means that this is **not** an independent array, but a shallow-copy. BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 55, 108, 202, 173, 233,  94,  13, 164, 125, 187,  83, 133,  61,  14,\n",
       "          60, 140, 231,  50, 111, 155],\n",
       "        [213, 160,  49,  27, 231,  63,  90, 211,  18, 199, 202, 211, 190, 234,\n",
       "          20, 170,  52, 129,  26,  82],\n",
       "        [175, 103, 161, 248,  86,  90, 206,  20,  14, 176, 183,  67, 172,   5,\n",
       "          49,  23, 244,  22, 144, 170],\n",
       "        [215,  69, 106,  86, 139,  97,  63, 237,  45, 145,  49, 160,  89,   7,\n",
       "         125, 137,  93, 133,  56, 145],\n",
       "        [169,  96,  31, 231, 134,  96,  88,  70,  91, 108, 223,  66,  28, 230,\n",
       "          91, 152,  35,  73, 101, 167]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_copy = t_random.view(5, 20)\n",
    "view_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_copy.fill_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original affected\n",
    "t_random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- to perform backpropogation in Deep Learning networks, we need to calculate all the necessary gradients.\n",
    "- this feature is integrated into PyTorch arrays directly:\n",
    "    - use the **require_grad** option\n",
    "    - simple example, define a variable **x = 1**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, 1, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass variable through a few simple operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y ** (3 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 5 * z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last variable that depended initially on x, is now w. So w needs to be optimised in respect to variable x. We can do this simply by calculating the gradients of w **dw/dx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[21.2132]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that we indeed obtain the correct gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.213203435596427"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 * (3 / 2) * (2**0.5) * 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "recover a numpy array from a PyTorch tensor or plot a PyTorch tensor with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.detach().numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sending tensors to a GPU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If pc has a compatible GPU, or if you run the notebook on Google Colab with a GPU runtime -> you can exploit Graphics card computing power"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will have to be \"pushed\" or \"pulled\" to and from that device. Can push entire networks but for the moment just send a tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU is a available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the data the the \"CUDA\" device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\")\n",
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1092, -0.7593, -1.3767,  0.4996,  0.7173],\n",
       "        [ 0.1082,  1.4408,  1.4879, -0.1904, -0.9103],\n",
       "        [-1.3160,  0.9041,  0.0470,  0.6126, -0.8336]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor = torch.randn((3, 5))\n",
    "mytensor = mytensor.to(dev)\n",
    "mytensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error below: We see here that we have again difficulties getting the tensor \"out\" of PyTorch. This time not because it's part of a gradient but because it lives on the GPU. So we need to first copy it back to the CPU first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mytensor\u001b[39m.\u001b[39;49mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "mytensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor_CPU = mytensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1092274 , -0.7592683 , -1.3767385 ,  0.4996251 ,  0.71728456],\n",
       "       [ 0.10819691,  1.4408439 ,  1.4879323 , -0.19036253, -0.9103441 ],\n",
       "       [-1.315988  ,  0.90409184,  0.04701529,  0.61258537, -0.8335832 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytensor_CPU.numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two potential troubleshooting areas:\n",
    "\n",
    "    - you migth need to detach it from the gradient calculation\n",
    "    - you migth need to pull it out of the GPU\n",
    "    - for NN computation, you might need to push your data (tensors) to the GPU\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a tensor of integers in the range 0-100 of size 16x16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 20, 97, 77, 72, 48,  5, 24, 23, 80, 10, 48, 58, 64, 47,  0],\n",
       "        [45, 73, 35,  0,  3,  4, 40, 74, 67, 75, 88, 24, 57,  4, 62, 55],\n",
       "        [97, 94, 73, 45, 32, 41, 93, 75, 36, 57, 53, 32, 92, 92,  7, 60],\n",
       "        [38, 90, 90, 75, 57, 64, 18, 31, 76, 74, 19, 70, 35, 56, 90, 87],\n",
       "        [30, 89, 61, 10, 49, 45, 90, 17, 35, 30, 24, 18, 24, 51,  8, 53],\n",
       "        [32, 40, 97,  7, 51, 55, 12, 92, 85,  7, 84, 71, 19,  4, 67, 87],\n",
       "        [53, 45, 98, 26, 29,  5, 74, 76, 95, 15, 55, 70, 68, 86, 18,  7],\n",
       "        [97, 26, 51, 94, 24, 41, 61, 11, 31, 41, 80, 81, 24, 53, 99, 19],\n",
       "        [75, 29, 29, 85,  9, 23, 34, 97, 35, 10, 44, 83, 63,  9, 25, 57],\n",
       "        [93, 53, 21, 28, 10, 64, 75, 53, 14, 52,  1, 83, 36, 79, 79, 17],\n",
       "        [80, 47, 94, 73, 75, 61, 69, 52, 34, 95, 34, 73, 88,  6, 29, 40],\n",
       "        [30, 82, 46, 32, 71, 42, 93, 31, 13, 43, 38,  6, 67, 90, 60, 23],\n",
       "        [ 4, 69, 99, 51, 85, 77,  1, 81, 28, 65, 64, 56, 54, 82, 51, 48],\n",
       "        [40, 43, 98,  2, 11, 53, 99, 65, 41, 21, 24, 66, 79, 67,  8, 97],\n",
       "        [32, 82, 38, 61, 92, 11, 74, 24, 28, 25, 47, 43, 56, 78,  5, 97],\n",
       "        [88, 69, 64, 15, 59, 46, 58, 48, 37, 78, 31, 61, 10, 75, 92,  1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_exercise = torch.randint(0, 100, (16, 16))\n",
    "t_exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Change its \"gradient-status\" by attaching it to gradient calculation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16., 29., 66., 35., 47., 30., 49., 55., 16., 49., 45., 15., 28., 43.,\n",
      "         58., 94.],\n",
      "        [91., 42., 41.,  6., 95., 38., 94., 48., 84.,  6., 80., 90., 64., 79.,\n",
      "         58., 10.],\n",
      "        [ 2., 95., 95.,  9., 82., 37., 36., 50., 76., 65.,  6., 73., 21., 79.,\n",
      "          6.,  6.],\n",
      "        [86., 63., 22., 65., 90., 77., 29., 84., 74., 89., 19., 61., 50., 73.,\n",
      "         24., 60.],\n",
      "        [52., 55., 96.,  1., 98., 36.,  0., 49., 37., 37., 15., 49., 16., 67.,\n",
      "         41., 78.],\n",
      "        [71., 62.,  5., 20., 79., 57., 71., 34., 52., 37., 25., 99., 18., 91.,\n",
      "         55., 39.],\n",
      "        [89., 87., 55., 10., 34., 96., 46., 47., 16., 72.,  8., 88., 14.,  2.,\n",
      "         99., 89.],\n",
      "        [37., 32., 78., 30., 55., 31., 76., 74., 19., 14., 75.,  1., 72., 90.,\n",
      "         64., 23.],\n",
      "        [15., 10., 14., 48., 90., 23.,  0., 13., 91., 56., 97.,  2., 86., 63.,\n",
      "          1., 70.],\n",
      "        [98., 77., 61., 57., 43., 30., 48., 19.,  1., 11., 90., 26., 88., 35.,\n",
      "          7., 21.],\n",
      "        [98., 89., 96., 12., 95., 73., 72., 18., 65., 17.,  8., 45., 14., 86.,\n",
      "          7., 25.],\n",
      "        [90., 99., 69., 11., 94., 90.,  8., 12., 65., 78., 38., 82., 47., 93.,\n",
      "         19., 68.],\n",
      "        [63., 89., 68., 41.,  3.,  3., 11., 48., 82., 77., 35., 91., 46., 89.,\n",
      "         23., 70.],\n",
      "        [72., 39., 60., 58.,  2., 88., 43.,  2., 57., 85., 45.,  3., 43., 84.,\n",
      "         94., 92.],\n",
      "        [10., 63., 25.,  4., 33., 13., 40., 85., 46., 40., 99., 42., 78., 50.,\n",
      "         87., 72.],\n",
      "        [75., 22., 69., 65., 59., 36., 40., 81.,  2., 62., 45., 77., 13., 71.,\n",
      "         99., 83.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t_exercise = torch.randint(0, 100, (16, 16), dtype=torch.float, requires_grad=True)\n",
    "print(t_exercise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve the problem appearing in (2.) by creating a float32 tensor and attaching the gradient again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57., 21., 18., 68., 27.,  6., 71.,  5., 86.,  6., 67., 95., 36., 14.,\n",
      "         38., 44.],\n",
      "        [16., 34., 41., 98.,  4., 80., 43., 50., 11., 74., 24., 77.,  3., 60.,\n",
      "         68., 23.],\n",
      "        [92., 10., 88., 78., 74.,  6., 40., 13., 52., 83., 72., 79., 13., 83.,\n",
      "         90., 99.],\n",
      "        [75., 73., 90., 95., 81., 59., 13., 16., 41., 98., 90., 20., 90., 72.,\n",
      "         10., 64.],\n",
      "        [97., 30., 62., 56., 45., 93., 99., 20., 78., 98., 48.,  1., 79., 95.,\n",
      "         66., 99.],\n",
      "        [10., 57., 97., 22., 54., 15., 36., 92., 28., 97., 41., 60., 54., 64.,\n",
      "         91., 28.],\n",
      "        [58., 53., 23., 56., 85., 66., 95., 11., 86., 94., 66., 57., 20., 12.,\n",
      "         70., 20.],\n",
      "        [15., 31., 57., 39., 67., 76., 51., 46., 55., 66.,  3., 90., 82., 46.,\n",
      "         60., 31.],\n",
      "        [92., 76., 15., 36., 70., 63., 28., 76., 19., 44., 68., 89., 30., 49.,\n",
      "         22., 63.],\n",
      "        [80., 55., 61., 76., 42., 70., 35., 32., 84., 44., 20., 52.,  4., 77.,\n",
      "         77., 81.],\n",
      "        [84., 62., 80.,  1., 80., 75., 62., 25., 34., 38., 32., 58., 60., 39.,\n",
      "         75., 17.],\n",
      "        [38., 11., 50., 31., 24., 60., 88., 98., 38., 82.,  9., 52., 85., 85.,\n",
      "         17., 59.],\n",
      "        [87., 53., 98., 77.,  4., 11.,  0., 32., 76., 75., 35., 33., 28., 86.,\n",
      "         64., 54.],\n",
      "        [14.,  3., 46., 57., 67., 44., 41., 40., 60., 81., 93., 68., 55.,  6.,\n",
      "         37., 54.],\n",
      "        [32., 54., 64.,  4., 35., 34.,  8., 29., 99., 22., 90., 65.,  3., 91.,\n",
      "         16., 35.],\n",
      "        [84., 14., 44., 10., 77.,  6., 90., 66., 32., 60., 29., 89., 87.,  0.,\n",
      "         63., 90.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "t_exercise = torch.randint(0, 100, (16, 16), dtype=torch.float32, requires_grad=True)\n",
    "print(t_exercise)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Flatten the array to 1d**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([57., 21., 18., 68., 27.,  6., 71.,  5., 86.,  6., 67., 95., 36., 14.,\n",
       "        38., 44., 16., 34., 41., 98.,  4., 80., 43., 50., 11., 74., 24., 77.,\n",
       "         3., 60., 68., 23., 92., 10., 88., 78., 74.,  6., 40., 13., 52., 83.,\n",
       "        72., 79., 13., 83., 90., 99., 75., 73., 90., 95., 81., 59., 13., 16.,\n",
       "        41., 98., 90., 20., 90., 72., 10., 64., 97., 30., 62., 56., 45., 93.,\n",
       "        99., 20., 78., 98., 48.,  1., 79., 95., 66., 99., 10., 57., 97., 22.,\n",
       "        54., 15., 36., 92., 28., 97., 41., 60., 54., 64., 91., 28., 58., 53.,\n",
       "        23., 56., 85., 66., 95., 11., 86., 94., 66., 57., 20., 12., 70., 20.,\n",
       "        15., 31., 57., 39., 67., 76., 51., 46., 55., 66.,  3., 90., 82., 46.,\n",
       "        60., 31., 92., 76., 15., 36., 70., 63., 28., 76., 19., 44., 68., 89.,\n",
       "        30., 49., 22., 63., 80., 55., 61., 76., 42., 70., 35., 32., 84., 44.,\n",
       "        20., 52.,  4., 77., 77., 81., 84., 62., 80.,  1., 80., 75., 62., 25.,\n",
       "        34., 38., 32., 58., 60., 39., 75., 17., 38., 11., 50., 31., 24., 60.,\n",
       "        88., 98., 38., 82.,  9., 52., 85., 85., 17., 59., 87., 53., 98., 77.,\n",
       "         4., 11.,  0., 32., 76., 75., 35., 33., 28., 86., 64., 54., 14.,  3.,\n",
       "        46., 57., 67., 44., 41., 40., 60., 81., 93., 68., 55.,  6., 37., 54.,\n",
       "        32., 54., 64.,  4., 35., 34.,  8., 29., 99., 22., 90., 65.,  3., 91.,\n",
       "        16., 35., 84., 14., 44., 10., 77.,  6., 90., 66., 32., 60., 29., 89.,\n",
       "        87.,  0., 63., 90.], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_tensor = t_exercise.flatten()\n",
    "flat_tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform your flat tensor to a numpy array**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor to Numpy: Detach it from the gradient calculation system to recover it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([57., 21., 18., 68., 27.,  6., 71.,  5., 86.,  6., 67., 95., 36.,\n",
       "       14., 38., 44., 16., 34., 41., 98.,  4., 80., 43., 50., 11., 74.,\n",
       "       24., 77.,  3., 60., 68., 23., 92., 10., 88., 78., 74.,  6., 40.,\n",
       "       13., 52., 83., 72., 79., 13., 83., 90., 99., 75., 73., 90., 95.,\n",
       "       81., 59., 13., 16., 41., 98., 90., 20., 90., 72., 10., 64., 97.,\n",
       "       30., 62., 56., 45., 93., 99., 20., 78., 98., 48.,  1., 79., 95.,\n",
       "       66., 99., 10., 57., 97., 22., 54., 15., 36., 92., 28., 97., 41.,\n",
       "       60., 54., 64., 91., 28., 58., 53., 23., 56., 85., 66., 95., 11.,\n",
       "       86., 94., 66., 57., 20., 12., 70., 20., 15., 31., 57., 39., 67.,\n",
       "       76., 51., 46., 55., 66.,  3., 90., 82., 46., 60., 31., 92., 76.,\n",
       "       15., 36., 70., 63., 28., 76., 19., 44., 68., 89., 30., 49., 22.,\n",
       "       63., 80., 55., 61., 76., 42., 70., 35., 32., 84., 44., 20., 52.,\n",
       "        4., 77., 77., 81., 84., 62., 80.,  1., 80., 75., 62., 25., 34.,\n",
       "       38., 32., 58., 60., 39., 75., 17., 38., 11., 50., 31., 24., 60.,\n",
       "       88., 98., 38., 82.,  9., 52., 85., 85., 17., 59., 87., 53., 98.,\n",
       "       77.,  4., 11.,  0., 32., 76., 75., 35., 33., 28., 86., 64., 54.,\n",
       "       14.,  3., 46., 57., 67., 44., 41., 40., 60., 81., 93., 68., 55.,\n",
       "        6., 37., 54., 32., 54., 64.,  4., 35., 34.,  8., 29., 99., 22.,\n",
       "       90., 65.,  3., 91., 16., 35., 84., 14., 44., 10., 77.,  6., 90.,\n",
       "       66., 32., 60., 29., 89., 87.,  0., 63., 90.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_from_tensor = flat_tensor.detach().numpy()\n",
    "numpy_from_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLImaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7be78ef86576dc85e4063c07c65a9db690a1cb6a564e4c0124da975355a61b8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
